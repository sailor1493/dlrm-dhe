{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Chanwoo Park 2024\n",
    "#\n",
    "\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "import sympy\n",
    "\n",
    "\n",
    "class DHEFFN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, k):\n",
    "        super(DHEFFN, self).__init__()\n",
    "        self.dense = nn.Linear(input_dim, output_dim)\n",
    "        # initialize weights\n",
    "        nn.init.uniform_(self.dense.weight, np.sqrt(1 / k))\n",
    "        self.bn = nn.BatchNorm1d(output_dim)\n",
    "        self.activation = nn.Mish(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def generate_random_primes(k, m):\n",
    "    # generate k random primes larger than m\n",
    "    p_list = []\n",
    "    for _ in range(k):\n",
    "        p = m\n",
    "        while not sympy.isprime(p):\n",
    "            p = np.random.randint(m, 2 * m)\n",
    "        p_list.append(p)\n",
    "\n",
    "    return torch.Tensor(p_list).type(torch.long)\n",
    "\n",
    "\n",
    "def generate_random_numbers(k, m):\n",
    "    # generate k random numbers in [1, m)\n",
    "    a_list = np.random.randint(1, m, k).tolist()\n",
    "    b_list = np.random.randint(1, m, k).tolist()\n",
    "    return torch.Tensor(a_list).type(torch.long), torch.Tensor(b_list).type(torch.long)\n",
    "\n",
    "\n",
    "class DHE(nn.Module):\n",
    "    r\"\"\"Computes sums or means over multiple feature embeddings, calculated with hash function and DNN networks.\n",
    "\n",
    "        * with ``mode=\"sum\"`` is equivalent to :class:`~torch.nn.Embedding` followed by ``torch.sum(dim=0)``,\n",
    "        * with ``mode=\"mean\"`` is equivalent to :class:`~torch.nn.Embedding` followed by ``torch.mean(dim=0)``,\n",
    "\n",
    "    Known Issues:\n",
    "\n",
    "    # TODO: update this chanwoo. arguments are not updated\n",
    "    Args:\n",
    "        num_categories (int): total number of unique categories. The input indices must be in\n",
    "                              0, 1, ..., num_categories - 1.\n",
    "        embedding_dim (list): list of sizes for each embedding vector in each table. If ``\"add\"``\n",
    "                              or ``\"mult\"`` operation are used, these embedding dimensions must be\n",
    "                              the same. If a single embedding_dim is used, then it will use this\n",
    "                              embedding_dim for both embedding tables.\n",
    "        num_collisions (int): number of collisions to enforce.\n",
    "        operation (string, optional): ``\"concat\"``, ``\"add\"``, or ``\"mult\". Specifies the operation\n",
    "                                      to compose embeddings. ``\"concat\"`` concatenates the embeddings,\n",
    "                                      ``\"add\"`` sums the embeddings, and ``\"mult\"`` multiplies\n",
    "                                      (component-wise) the embeddings.\n",
    "                                      Default: ``\"mult\"``\n",
    "        max_norm (float, optional): If given, each embedding vector with norm larger than :attr:`max_norm`\n",
    "                                    is renormalized to have norm :attr:`max_norm`.\n",
    "        norm_type (float, optional): The p of the p-norm to compute for the :attr:`max_norm` option. Default ``2``.\n",
    "        scale_grad_by_freq (boolean, optional): if given, this will scale gradients by the inverse of frequency of\n",
    "                                                the words in the mini-batch. Default ``False``.\n",
    "                                                Note: this option is not supported when ``mode=\"max\"``.\n",
    "        mode (string, optional): ``\"sum\"``, ``\"mean\"`` or ``\"max\"``. Specifies the way to reduce the bag.\n",
    "                                 ``\"sum\"`` computes the weighted sum, taking :attr:`per_sample_weights`\n",
    "                                 into consideration. ``\"mean\"`` computes the average of the values\n",
    "                                 in the bag, ``\"max\"`` computes the max value over each bag.\n",
    "                                 Default: ``\"mean\"``\n",
    "        sparse (bool, optional): if ``True``, gradient w.r.t. :attr:`weight` matrix will be a sparse tensor. See\n",
    "                                 Notes for more details regarding sparse gradients. Note: this option is not\n",
    "                                 supported when ``mode=\"max\"``.\n",
    "\n",
    "    # TODO: update this chanwoo\n",
    "    Attributes:\n",
    "        weight (Tensor): the learnable weights of each embedding table is the module of shape\n",
    "                         `(num_embeddings, embedding_dim)` initialized using a uniform distribution\n",
    "                         with sqrt(1 / num_categories).\n",
    "\n",
    "    Inputs: :attr:`input` (LongTensor), :attr:`offsets` (LongTensor, optional), and\n",
    "        :attr:`per_index_weights` (Tensor, optional)\n",
    "\n",
    "        - If :attr:`input` is 2D of shape `(B, N)`,\n",
    "\n",
    "          it will be treated as ``B`` bags (sequences) each of fixed length ``N``, and\n",
    "          this will return ``B`` values aggregated in a way depending on the :attr:`mode`.\n",
    "          :attr:`offsets` is ignored and required to be ``None`` in this case.\n",
    "\n",
    "        - If :attr:`input` is 1D of shape `(N)`,\n",
    "\n",
    "          it will be treated as a concatenation of multiple bags (sequences).\n",
    "          :attr:`offsets` is required to be a 1D tensor containing the\n",
    "          starting index positions of each bag in :attr:`input`. Therefore,\n",
    "          for :attr:`offsets` of shape `(B)`, :attr:`input` will be viewed as\n",
    "          having ``B`` bags. Empty bags (i.e., having 0-length) will have\n",
    "          returned vectors filled by zeros.\n",
    "\n",
    "        per_sample_weights (Tensor, optional): a tensor of float / double weights, or None\n",
    "            to indicate all weights should be taken to be ``1``. If specified, :attr:`per_sample_weights`\n",
    "            must have exactly the same shape as input and is treated as having the same\n",
    "            :attr:`offsets`, if those are not ``None``. Only supported for ``mode='sum'``.\n",
    "\n",
    "\n",
    "    Output shape: `(B, embedding_dim)`\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        a_list=None,\n",
    "        b_list=None,\n",
    "        p_list=None,\n",
    "        embedding_dim=32,\n",
    "        k=1024,  # number of hash function\n",
    "        h=5,  # number of hidden layers\n",
    "        d_nn=1800,  # dimension of hidden layers\n",
    "        m=1000000,\n",
    "        uniform=False,\n",
    "        reduce=\"sum\",\n",
    "    ):\n",
    "        super(DHE, self).__init__()\n",
    "        if a_list is None or b_list is None or p_list is None:\n",
    "            a_list, b_list = generate_random_numbers(k, m)\n",
    "            p_list = generate_random_primes(k, m)\n",
    "        assert reduce in [\n",
    "            \"sum\",\n",
    "            \"mean\",\n",
    "        ], f\"reduce must be 'sum' or 'mean', but got {reduce}\"\n",
    "        self.k = k\n",
    "        self.h = h\n",
    "        self.d_nn = d_nn\n",
    "        self.m = m\n",
    "        self.reduce = reduce\n",
    "\n",
    "        self.a_list = a_list\n",
    "        self.b_list = b_list\n",
    "        self.p_list = p_list\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        # first layer\n",
    "        # in: k, out: d_nn\n",
    "        self.layers.append(DHEFFN(k, d_nn, k))\n",
    "        # hidden layers\n",
    "        for _ in range(1, h - 1):\n",
    "            self.layers.append(DHEFFN(d_nn, d_nn, k))\n",
    "        # last layer\n",
    "        # in: d_nn, out: embedding_dim\n",
    "        self.layers.append(DHEFFN(d_nn, embedding_dim, k))\n",
    "        self.layers= nn.Sequential(*self.layers)\n",
    "        self.uniform = uniform\n",
    "\n",
    "    def _transform(self, x):\n",
    "        # input: b x s\n",
    "        # transform: b x s x 1024\n",
    "        x = x.unsqueeze(-1).expand(-1, -1, self.k)\n",
    "        print(x)\n",
    "        \n",
    "        # transform: x[b,i] = (a_list[i] * x[i] + b_list[i]) % p_list[i] % m\n",
    "        x = (self.a_list * x + self.b_list) % self.p_list % self.m + 1\n",
    "        print(x)\n",
    "        x = (x - 1) / (self.m - 1) \n",
    "        e = torch.zeros_like(x)\n",
    "        print(x)\n",
    "        x_even = x[:, 0::2]\n",
    "        x_odd = x[:, 1::2]\n",
    "        print(x_even)\n",
    "        print(x_odd)\n",
    "        e[:, 0::2] = torch.sqrt(-2 * torch.log(x_even)) * torch.cos(2 * torch.pi * x_odd)\n",
    "        e[:, 1::2] = torch.sqrt(-2 * torch.log(x_even)) * torch.sin(2 * torch.pi * x_odd)\n",
    "        print(e)\n",
    "        # reduce operation\n",
    "        # e[s, k] -> e[k]\n",
    "        if self.reduce == \"sum\":\n",
    "            e = e.sum(dim=0)\n",
    "        elif self.reduce == \"mean\":\n",
    "            e = e.mean(dim=0)\n",
    "        return e\n",
    "\n",
    "\n",
    "    def forward(self, input, offsets, per_sample_weights=None):\n",
    "        # input: Sequence of indices into the embedding tables\n",
    "        # offsets:  It specifies the starting index position of each bag (sequence) in input.\n",
    "        # use offset to separate inputs\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        input_rearranged = [input[offsets[i] : offsets[i + 1]] for i in range(offsets.shape[0] - 1)]\n",
    "        transformed = self._transform(input_rearranged)\n",
    "        output = self.layers(transformed)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhe = DHE(64, \"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2, 2, 2,  ..., 2, 2, 2],\n",
      "         [3, 3, 3,  ..., 3, 3, 3]],\n",
      "\n",
      "        [[4, 4, 4,  ..., 4, 4, 4],\n",
      "         [5, 5, 5,  ..., 5, 5, 5]]])\n",
      "tensor([[[720534, 601089, 102960,  ..., 878739, 473278, 125246],\n",
      "         [776067, 166794, 606569,  ..., 965861, 651973, 739230]],\n",
      "\n",
      "        [[831600, 974050, 183145,  ...,  52983, 830668, 353214],\n",
      "         [887133, 539755, 686754,  ..., 140105,   9363,   7255]]])\n",
      "tensor([[[0.7205, 0.6011, 0.1030,  ..., 0.8787, 0.4733, 0.1252],\n",
      "         [0.7761, 0.1668, 0.6066,  ..., 0.9659, 0.6520, 0.7392]],\n",
      "\n",
      "        [[0.8316, 0.9740, 0.1831,  ..., 0.0530, 0.8307, 0.3532],\n",
      "         [0.8871, 0.5398, 0.6868,  ..., 0.1401, 0.0094, 0.0073]]])\n",
      "tensor([[[0.7205, 0.6011, 0.1030,  ..., 0.8787, 0.4733, 0.1252]],\n",
      "\n",
      "        [[0.8316, 0.9740, 0.1831,  ..., 0.0530, 0.8307, 0.3532]]])\n",
      "tensor([[[0.7761, 0.1668, 0.6066,  ..., 0.9659, 0.6520, 0.7392]],\n",
      "\n",
      "        [[0.8871, 0.5398, 0.6868,  ..., 0.1401, 0.0094, 0.0073]]])\n",
      "tensor([[[ 0.1320,  0.5038, -1.6719,  ...,  0.4968, -0.7066, -0.1378],\n",
      "         [-0.7988,  0.8742, -1.3235,  ..., -0.1082, -0.9984, -2.0337]],\n",
      "\n",
      "        [[ 0.4609, -0.2222, -0.7131,  ...,  1.5439,  0.6081,  1.4412],\n",
      "         [-0.3955, -0.0567, -1.6990,  ...,  1.8687,  0.0358,  0.0657]]])\n",
      "tensor([[ 0.5929,  0.2816, -2.3850,  ...,  2.0407, -0.0986,  1.3034],\n",
      "        [-1.1943,  0.8175, -3.0224,  ...,  1.7605, -0.9626, -1.9680]])\n"
     ]
    }
   ],
   "source": [
    "it = torch.tensor([[2,3],[4,5]])\n",
    "transformed = dhe._transform(it)\n",
    "print(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (-1) isn't allowed in a leading, non-existing dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[135], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m ,\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m]\n\u001b[1;32m      2\u001b[0m offsets\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdhe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43moffsets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[132], line 200\u001b[0m, in \u001b[0;36mDHE.forward\u001b[0;34m(self, input, offsets, per_sample_weights)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, offsets, per_sample_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# input: Sequence of indices into the embedding tables\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# offsets:  It specifies the starting index position of each bag (sequence) in input.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;66;03m# use offset to separate inputs\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     input_rearranged \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28minput\u001b[39m[offsets[i] : offsets[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(offsets\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m--> 200\u001b[0m     transformed \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m input_rearranged])\n\u001b[1;32m    201\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers(transformed)\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "Cell \u001b[0;32mIn[132], line 200\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, offsets, per_sample_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# input: Sequence of indices into the embedding tables\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# offsets:  It specifies the starting index position of each bag (sequence) in input.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;66;03m# use offset to separate inputs\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     input_rearranged \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28minput\u001b[39m[offsets[i] : offsets[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(offsets\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m--> 200\u001b[0m     transformed \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m input_rearranged])\n\u001b[1;32m    201\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers(transformed)\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "Cell \u001b[0;32mIn[132], line 168\u001b[0m, in \u001b[0;36mDHE._transform\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# input: b x s\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# transform: b x s x 1024\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x)\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m# transform: x[b,i] = (a_list[i] * x[i] + b_list[i]) % p_list[i] % m\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (-1) isn't allowed in a leading, non-existing dimension 0"
     ]
    }
   ],
   "source": [
    "inputs = [1, 2 ,5, 6]\n",
    "offsets=[0,3,4]\n",
    "res = dhe(torch.tensor(inputs), torch.tensor(offsets))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
